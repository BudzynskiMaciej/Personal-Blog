<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM? | Budzyński Maciej - blog</title>
<meta name=keywords content><meta name=description content="Artificial Intelligence (AI) has become one of the most transformative technologies of our time. From chatbots to autonomous vehicles, AI is reshaping industries and our daily lives. In this article, I will explain what AI is, how Large Language Models (LLMs) work, and how you can run AI models locally using tools like Ollama and LM Studio.
What is Artificial Intelligence?
Artificial Intelligence (AI) refers to computer systems capable of performing tasks that typically require human intelligence. These tasks include understanding natural language, recognizing images, making decisions, and even generating creative content. AI is broadly categorized into:"><meta name=author content="Maciej Budzyński"><link rel=canonical href=https://blog.budzynskimaciej.pl/en/post/ai-and-llms/><meta name=google-site-verification content="G-FTCMYPN4XN"><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=pl href=https://blog.budzynskimaciej.pl/post/ai-and-llms/><link rel=alternate hreflang=en href=https://blog.budzynskimaciej.pl/en/post/ai-and-llms/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://blog.budzynskimaciej.pl/en/post/ai-and-llms/"><meta property="og:site_name" content="Budzyński Maciej - blog"><meta property="og:title" content="AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM?"><meta property="og:description" content="Artificial Intelligence (AI) has become one of the most transformative technologies of our time. From chatbots to autonomous vehicles, AI is reshaping industries and our daily lives. In this article, I will explain what AI is, how Large Language Models (LLMs) work, and how you can run AI models locally using tools like Ollama and LM Studio.
What is Artificial Intelligence? Artificial Intelligence (AI) refers to computer systems capable of performing tasks that typically require human intelligence. These tasks include understanding natural language, recognizing images, making decisions, and even generating creative content. AI is broadly categorized into:"><meta property="og:locale" content="en-US"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2025-02-10T18:00:00+02:00"><meta property="article:modified_time" content="2025-02-10T18:00:00+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM?"><meta name=twitter:description content="Artificial Intelligence (AI) has become one of the most transformative technologies of our time. From chatbots to autonomous vehicles, AI is reshaping industries and our daily lives. In this article, I will explain what AI is, how Large Language Models (LLMs) work, and how you can run AI models locally using tools like Ollama and LM Studio.
What is Artificial Intelligence?
Artificial Intelligence (AI) refers to computer systems capable of performing tasks that typically require human intelligence. These tasks include understanding natural language, recognizing images, making decisions, and even generating creative content. AI is broadly categorized into:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.budzynskimaciej.pl/en/post/"},{"@type":"ListItem","position":2,"name":"AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM?","item":"https://blog.budzynskimaciej.pl/en/post/ai-and-llms/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM?","name":"AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM?","description":"Artificial Intelligence (AI) has become one of the most transformative technologies of our time. From chatbots to autonomous vehicles, AI is reshaping industries and our daily lives. In this article, I will explain what AI is, how Large Language Models (LLMs) work, and how you can run AI models locally using tools like Ollama and LM Studio.\nWhat is Artificial Intelligence? Artificial Intelligence (AI) refers to computer systems capable of performing tasks that typically require human intelligence. These tasks include understanding natural language, recognizing images, making decisions, and even generating creative content. AI is broadly categorized into:\n","keywords":[],"articleBody":"Artificial Intelligence (AI) has become one of the most transformative technologies of our time. From chatbots to autonomous vehicles, AI is reshaping industries and our daily lives. In this article, I will explain what AI is, how Large Language Models (LLMs) work, and how you can run AI models locally using tools like Ollama and LM Studio.\nWhat is Artificial Intelligence? Artificial Intelligence (AI) refers to computer systems capable of performing tasks that typically require human intelligence. These tasks include understanding natural language, recognizing images, making decisions, and even generating creative content. AI is broadly categorized into:\nNarrow AI – Specialized AI designed for specific tasks, like voice assistants (Siri, Alexa) or recommendation systems. General AI – A hypothetical AI that can perform any intellectual task a human can do. Superintelligent AI – A concept where AI surpasses human intelligence in all aspects. What are Large Language Models (LLMs)? Large Language Models (LLMs) are a subset of AI designed to understand and generate human-like text. These models are trained on vast amounts of text data and use deep learning techniques to predict and generate coherent responses. Popular LLMs include:\nGPT (Generative Pre-trained Transformer) – Developed by OpenAI. LLaMA (Large Language Model Meta AI) – Open-source model by Meta. Mistral \u0026 Mixtral – Advanced LLMs focused on efficiency and performance. How LLMs Work LLMs operate using deep learning models based on neural networks, specifically transformer architectures. The key components of an LLM include:\nTokenization – Breaking text into smaller units (tokens) for processing. Training on Large Datasets – Learning from billions of words. Fine-tuning – Adjusting the model for specific tasks like code generation or translation. Applications of LLMs Large Language Models have a wide range of applications, including:\nConversational AI – Used in chatbots like ChatGPT, customer support agents, and virtual assistants. Content Generation – Writing blog articles, generating reports, or even creating poetry and fiction. Code Assistance – AI-powered coding assistants like GitHub Copilot help developers by generating code snippets and completing functions. Translation Services – Automating language translation with tools like DeepL and Google Translate. Medical Research – Assisting in diagnosing conditions, summarizing medical papers, and generating clinical notes. Search and Information Retrieval – Enhancing search engines with AI-powered summarization and contextual understanding. Challenges and Limitations Despite their capabilities, LLMs also have challenges and limitations:\nBias in Training Data – Since they learn from vast text sources, they can inherit biases present in those datasets. Computational Requirements – Running large-scale models requires significant processing power, especially for real-time applications. Lack of True Understanding – While LLMs generate text based on patterns, they do not possess genuine comprehension or reasoning abilities. Ethical Concerns – Misuse of AI-generated content for misinformation, deepfakes, or plagiarism. As research continues, improvements in AI safety, efficiency, and ethical guidelines will shape the future of LLM applications.\nRunning AI Models Locally While most AI applications rely on cloud-based models, running AI models locally offers several benefits:\nPrivacy – Your data stays on your machine. Speed – No dependency on internet connectivity. Customization – Ability to fine-tune models for specific use cases. Installing and Using Local AI Tools 1. Ollama Ollama is a tool for running LLMs on your local machine with minimal setup.\nInstallation Windows, Mac \u0026 Linux:\nDownload the executable from ollama.ai and install it. Follow the on-screen instructions to complete the installation. Running a Model ollama run mistral This command downloads and runs the Mistral model locally. Ollama allows you to load and run different LLMs efficiently while leveraging your hardware.\nFeatures of Ollama Lightweight Execution – Optimized to run models efficiently. Multiple Model Support – Load different LLMs as needed. Ease of Use – Simple command-line interface for quick access. 2. LM Studio LM Studio provides a GUI for running local AI models with ease.\nInstallation Download LM Studio from lmstudio.ai and install it. Using LM Studio Open the application. Download a compatible model (e.g., LLaMA 2, Mistral). Interact with the model via the built-in chat interface. Features of LM Studio User-Friendly Interface – No need for command-line interactions. Model Management – Easily download and switch between different AI models. Performance Optimization – Ensures smooth operation on various hardware configurations. DeepSeek R1: A Powerful Open-Source LLM What is DeepSeek R1? DeepSeek R1 is an open-source large language model (LLM) developed by the Chinese AI company DeepSeek. Designed to excel in complex reasoning tasks, including mathematics, coding, and logical problem-solving, it achieves performance comparable to leading models like OpenAI’s GPT-4. Notably, DeepSeek R1 was developed with significantly fewer resources, utilizing only about 2,000 GPUs and incurring a cost of approximately $5.6 million, which is a fraction of the expenditure for similar models.\nPerformance In benchmark evaluations, DeepSeek R1 has demonstrated strong performance across various domains:\nMathematics: Achieved a 79.8% Pass@1 score on the AIME 2024 benchmark. Coding: Performed competitively in code-related tasks, with a 49.2% score on the SWE-bench Verified benchmark, slightly surpassing OpenAI’s GPT-4. Reasoning: Demonstrated effective logical reasoning capabilities, making it suitable for complex problem-solving applications. Running DeepSeek R1 Locally with Ollama Step 1: Download and Run DeepSeek R1 Open your terminal or command prompt and execute the following command to download and run the DeepSeek R1 model:\nollama run deepseek-r1 This command will download the DeepSeek R1 model and run it locally on your machine.\nStep 2: Running DeepSeek R1 in the Background To keep DeepSeek R1 running continuously and accessible via an API, start the Ollama server:\nollama serve This will make the model available for integration with other applications.\nHardware Considerations DeepSeek R1 offers various model sizes, ranging from 1.5 billion to 671 billion parameters. The 671B model is the original DeepSeek R1, while the smaller versions are distilled models based on Qwen and Llama architectures. If your hardware cannot support the full 671B model, you can run a smaller version by specifying the desired model size in the command. Replace X with the parameter size you want to use (e.g., 1.5b, 7b, 8b, 14b, 32b, 70b):\nollama run deepseek-r1:Xb This flexibility allows you to utilize DeepSeek R1’s capabilities even on hardware with limited resources.\nAccessing DeepSeek R1 via API Once the Ollama server is running, you can interact with DeepSeek R1 through an API. For example, using curl:\ncurl http://localhost:11434/api/chat -d '{ \"model\": \"deepseek-r1\", \"messages\": [{ \"role\": \"user\", \"content\": \"Solve: 25 * 25\" }], \"stream\": false }' This command sends a request to the model to solve the multiplication problem.\nUsing DeepSeek R1 in Python To integrate DeepSeek R1 into Python applications, install the Ollama Python package:\npip install ollama Then, use the following script to interact with the model:\nimport ollama response = ollama.chat( model=\"deepseek-r1\", messages=[ {\"role\": \"user\", \"content\": \"Explain Newton's second law of motion\"}, ], ) print(response[\"message\"][\"content\"]) This script sends a prompt to DeepSeek R1 and prints the model’s response.\nConsiderations While DeepSeek R1 offers advanced capabilities, it’s important to be aware of certain considerations:\nContent Moderation: Reports indicate that DeepSeek R1 may provide information that is potentially harmful or sensitive, such as details on modifying bird flu viruses or promoting self-harm. This raises concerns about the model’s safety and the effectiveness of its content moderation mechanisms. Data Privacy: As with any AI model, it’s crucial to handle data responsibly and be mindful of privacy implications, especially when deploying the model in applications that process sensitive information. Conclusion AI and LLMs are revolutionizing technology, and now you can run powerful AI models locally on your machine. Whether you prefer the command-line simplicity of Ollama or the user-friendly interface of LM Studio, local AI tools are becoming more accessible than ever. Experiment, explore, and harness the power of AI on your own terms!\nRunning AI models locally is an exciting opportunity for developers, researchers, and enthusiasts alike. It enables deeper control, improved privacy, and efficient experimentation without relying on cloud-based services. With advancements in hardware acceleration, running large-scale models on consumer machines is becoming more practical.\nDeepSeek R1 is a powerful and cost-effective alternative to leading proprietary LLMs, making it an attractive choice for researchers, developers, and AI enthusiasts. By running it locally with Ollama, users can take advantage of its advanced reasoning capabilities while maintaining control over their AI infrastructure. Whether for coding, mathematics, or general problem-solving, DeepSeek R1 is a promising open-source solution for AI-driven applications.\nArticle generated using artificial intelligence.\n","wordCount":"1387","inLanguage":"en","datePublished":"2025-02-10T18:00:00+02:00","dateModified":"2025-02-10T18:00:00+02:00","author":{"@type":"Person","name":"Maciej Budzyński"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.budzynskimaciej.pl/en/post/ai-and-llms/"},"publisher":{"@type":"Organization","name":"Budzyński Maciej - blog","logo":{"@type":"ImageObject","url":"https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.budzynskimaciej.pl/en/ accesskey=h title="Home (Alt + H)"><img src=https://blog.budzynskimaciej.pl/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://blog.budzynskimaciej.pl/ title=Polski aria-label=Polski>Polski</a></li></ul></div></div><ul id=menu><li><a href=https://blog.budzynskimaciej.pl/en/about/ title=About><span>About</span></a></li><li><a href=https://blog.budzynskimaciej.pl/en/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://blog.budzynskimaciej.pl/en/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://blog.budzynskimaciej.pl/en/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://blog.budzynskimaciej.pl/en/entags/ title=Tags><span>Tags</span></a></li><li><a href=https://budzynskimaciej.pl/ title=Portfolio><span>Portfolio</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.budzynskimaciej.pl/en/>Home</a>&nbsp;»&nbsp;<a href=https://blog.budzynskimaciej.pl/en/post/>Posts</a></div><h1 class="post-title entry-hint-parent">AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM?</h1><div class=post-meta><span title='2025-02-10 18:00:00 +0200 +0200'>February 10, 2025</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1387 words&nbsp;·&nbsp;Maciej Budzyński&nbsp;|&nbsp;Translations:<ul class=i18n_list><li><a href=https://blog.budzynskimaciej.pl/post/ai-and-llms/>Polski</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/BudzynskiMaciej/Personal-Blog-Source/blob/master/content/post/ai-and-llms.en.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#how-llms-work>How LLMs Work</a><ul><li><a href=#applications-of-llms>Applications of LLMs</a></li><li><a href=#challenges-and-limitations>Challenges and Limitations</a></li></ul></li></ul><ul><li><a href=#installing-and-using-local-ai-tools>Installing and Using Local AI Tools</a><ul><li><a href=#1-ollama>1. Ollama</a></li><li><a href=#2-lm-studio>2. LM Studio</a></li></ul></li></ul><ul><li><a href=#what-is-deepseek-r1>What is DeepSeek R1?</a><ul><li><a href=#performance>Performance</a></li></ul></li><li><a href=#running-deepseek-r1-locally-with-ollama>Running DeepSeek R1 Locally with Ollama</a><ul><li><a href=#step-1-download-and-run-deepseek-r1>Step 1: Download and Run DeepSeek R1</a></li><li><a href=#step-2-running-deepseek-r1-in-the-background>Step 2: Running DeepSeek R1 in the Background</a></li><li><a href=#hardware-considerations>Hardware Considerations</a></li><li><a href=#accessing-deepseek-r1-via-api>Accessing DeepSeek R1 via API</a></li><li><a href=#using-deepseek-r1-in-python>Using DeepSeek R1 in Python</a></li></ul></li><li><a href=#considerations>Considerations</a></li></ul></nav></div></details></div><div class=post-content><p>Artificial Intelligence (AI) has become one of the most transformative technologies of our time. From chatbots to autonomous vehicles, AI is reshaping industries and our daily lives. In this article, I will explain what AI is, how Large Language Models (LLMs) work, and how you can run AI models locally using tools like Ollama and LM Studio.</p><h1 id=what-is-artificial-intelligence>What is Artificial Intelligence?<a hidden class=anchor aria-hidden=true href=#what-is-artificial-intelligence>#</a></h1><p>Artificial Intelligence (AI) refers to computer systems capable of performing tasks that typically require human intelligence. These tasks include understanding natural language, recognizing images, making decisions, and even generating creative content. AI is broadly categorized into:</p><ul><li><strong>Narrow AI</strong> – Specialized AI designed for specific tasks, like voice assistants (Siri, Alexa) or recommendation systems.</li><li><strong>General AI</strong> – A hypothetical AI that can perform any intellectual task a human can do.</li><li><strong>Superintelligent AI</strong> – A concept where AI surpasses human intelligence in all aspects.</li></ul><h1 id=what-are-large-language-models-llms>What are Large Language Models (LLMs)?<a hidden class=anchor aria-hidden=true href=#what-are-large-language-models-llms>#</a></h1><p>Large Language Models (LLMs) are a subset of AI designed to understand and generate human-like text. These models are trained on vast amounts of text data and use deep learning techniques to predict and generate coherent responses. Popular LLMs include:</p><ul><li><strong>GPT (Generative Pre-trained Transformer)</strong> – Developed by OpenAI.</li><li><strong>LLaMA (Large Language Model Meta AI)</strong> – Open-source model by Meta.</li><li><strong>Mistral & Mixtral</strong> – Advanced LLMs focused on efficiency and performance.</li></ul><h2 id=how-llms-work>How LLMs Work<a hidden class=anchor aria-hidden=true href=#how-llms-work>#</a></h2><p>LLMs operate using deep learning models based on neural networks, specifically transformer architectures. The key components of an LLM include:</p><ul><li><strong>Tokenization</strong> – Breaking text into smaller units (tokens) for processing.</li><li><strong>Training on Large Datasets</strong> – Learning from billions of words.</li><li><strong>Fine-tuning</strong> – Adjusting the model for specific tasks like code generation or translation.</li></ul><h3 id=applications-of-llms>Applications of LLMs<a hidden class=anchor aria-hidden=true href=#applications-of-llms>#</a></h3><p>Large Language Models have a wide range of applications, including:</p><ul><li><strong>Conversational AI</strong> – Used in chatbots like ChatGPT, customer support agents, and virtual assistants.</li><li><strong>Content Generation</strong> – Writing blog articles, generating reports, or even creating poetry and fiction.</li><li><strong>Code Assistance</strong> – AI-powered coding assistants like GitHub Copilot help developers by generating code snippets and completing functions.</li><li><strong>Translation Services</strong> – Automating language translation with tools like DeepL and Google Translate.</li><li><strong>Medical Research</strong> – Assisting in diagnosing conditions, summarizing medical papers, and generating clinical notes.</li><li><strong>Search and Information Retrieval</strong> – Enhancing search engines with AI-powered summarization and contextual understanding.</li></ul><h3 id=challenges-and-limitations>Challenges and Limitations<a hidden class=anchor aria-hidden=true href=#challenges-and-limitations>#</a></h3><p>Despite their capabilities, LLMs also have challenges and limitations:</p><ul><li><strong>Bias in Training Data</strong> – Since they learn from vast text sources, they can inherit biases present in those datasets.</li><li><strong>Computational Requirements</strong> – Running large-scale models requires significant processing power, especially for real-time applications.</li><li><strong>Lack of True Understanding</strong> – While LLMs generate text based on patterns, they do not possess genuine comprehension or reasoning abilities.</li><li><strong>Ethical Concerns</strong> – Misuse of AI-generated content for misinformation, deepfakes, or plagiarism.</li></ul><p>As research continues, improvements in AI safety, efficiency, and ethical guidelines will shape the future of LLM applications.</p><h1 id=running-ai-models-locally>Running AI Models Locally<a hidden class=anchor aria-hidden=true href=#running-ai-models-locally>#</a></h1><p>While most AI applications rely on cloud-based models, running AI models locally offers several benefits:</p><ul><li><strong>Privacy</strong> – Your data stays on your machine.</li><li><strong>Speed</strong> – No dependency on internet connectivity.</li><li><strong>Customization</strong> – Ability to fine-tune models for specific use cases.</li></ul><h2 id=installing-and-using-local-ai-tools>Installing and Using Local AI Tools<a hidden class=anchor aria-hidden=true href=#installing-and-using-local-ai-tools>#</a></h2><h3 id=1-ollama>1. Ollama<a hidden class=anchor aria-hidden=true href=#1-ollama>#</a></h3><p>Ollama is a tool for running LLMs on your local machine with minimal setup.</p><h4 id=installation>Installation<a hidden class=anchor aria-hidden=true href=#installation>#</a></h4><p><strong>Windows, Mac & Linux:</strong></p><ul><li>Download the executable from <a href=https://ollama.ai/>ollama.ai</a> and install it.</li><li>Follow the on-screen instructions to complete the installation.</li></ul><h4 id=running-a-model>Running a Model<a hidden class=anchor aria-hidden=true href=#running-a-model>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ollama run mistral
</span></span></code></pre></div><p>This command downloads and runs the Mistral model locally. Ollama allows you to load and run different LLMs efficiently while leveraging your hardware.</p><h4 id=features-of-ollama>Features of Ollama<a hidden class=anchor aria-hidden=true href=#features-of-ollama>#</a></h4><ul><li><strong>Lightweight Execution</strong> – Optimized to run models efficiently.</li><li><strong>Multiple Model Support</strong> – Load different LLMs as needed.</li><li><strong>Ease of Use</strong> – Simple command-line interface for quick access.</li></ul><h3 id=2-lm-studio>2. LM Studio<a hidden class=anchor aria-hidden=true href=#2-lm-studio>#</a></h3><p>LM Studio provides a GUI for running local AI models with ease.</p><h4 id=installation-1>Installation<a hidden class=anchor aria-hidden=true href=#installation-1>#</a></h4><ul><li>Download LM Studio from <a href=https://lmstudio.ai/>lmstudio.ai</a> and install it.</li></ul><h4 id=using-lm-studio>Using LM Studio<a hidden class=anchor aria-hidden=true href=#using-lm-studio>#</a></h4><ol><li>Open the application.</li><li>Download a compatible model (e.g., LLaMA 2, Mistral).</li><li>Interact with the model via the built-in chat interface.</li></ol><h4 id=features-of-lm-studio>Features of LM Studio<a hidden class=anchor aria-hidden=true href=#features-of-lm-studio>#</a></h4><ul><li><strong>User-Friendly Interface</strong> – No need for command-line interactions.</li><li><strong>Model Management</strong> – Easily download and switch between different AI models.</li><li><strong>Performance Optimization</strong> – Ensures smooth operation on various hardware configurations.</li></ul><h1 id=deepseek-r1-a-powerful-open-source-llm>DeepSeek R1: A Powerful Open-Source LLM<a hidden class=anchor aria-hidden=true href=#deepseek-r1-a-powerful-open-source-llm>#</a></h1><h2 id=what-is-deepseek-r1>What is DeepSeek R1?<a hidden class=anchor aria-hidden=true href=#what-is-deepseek-r1>#</a></h2><p>DeepSeek R1 is an open-source large language model (LLM) developed by the Chinese AI company DeepSeek. Designed to excel in complex reasoning tasks, including mathematics, coding, and logical problem-solving, it achieves performance comparable to leading models like OpenAI&rsquo;s GPT-4. Notably, DeepSeek R1 was developed with significantly fewer resources, utilizing only about 2,000 GPUs and incurring a cost of approximately $5.6 million, which is a fraction of the expenditure for similar models.</p><h3 id=performance>Performance<a hidden class=anchor aria-hidden=true href=#performance>#</a></h3><p>In benchmark evaluations, DeepSeek R1 has demonstrated strong performance across various domains:</p><ul><li><strong>Mathematics</strong>: Achieved a 79.8% Pass@1 score on the AIME 2024 benchmark.</li><li><strong>Coding</strong>: Performed competitively in code-related tasks, with a 49.2% score on the SWE-bench Verified benchmark, slightly surpassing OpenAI&rsquo;s GPT-4.</li><li><strong>Reasoning</strong>: Demonstrated effective logical reasoning capabilities, making it suitable for complex problem-solving applications.</li></ul><h2 id=running-deepseek-r1-locally-with-ollama>Running DeepSeek R1 Locally with Ollama<a hidden class=anchor aria-hidden=true href=#running-deepseek-r1-locally-with-ollama>#</a></h2><h3 id=step-1-download-and-run-deepseek-r1>Step 1: Download and Run DeepSeek R1<a hidden class=anchor aria-hidden=true href=#step-1-download-and-run-deepseek-r1>#</a></h3><p>Open your terminal or command prompt and execute the following command to download and run the DeepSeek R1 model:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ollama run deepseek-r1
</span></span></code></pre></div><p>This command will download the DeepSeek R1 model and run it locally on your machine.</p><h3 id=step-2-running-deepseek-r1-in-the-background>Step 2: Running DeepSeek R1 in the Background<a hidden class=anchor aria-hidden=true href=#step-2-running-deepseek-r1-in-the-background>#</a></h3><p>To keep DeepSeek R1 running continuously and accessible via an API, start the Ollama server:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ollama serve
</span></span></code></pre></div><p>This will make the model available for integration with other applications.</p><h3 id=hardware-considerations>Hardware Considerations<a hidden class=anchor aria-hidden=true href=#hardware-considerations>#</a></h3><p>DeepSeek R1 offers various model sizes, ranging from 1.5 billion to 671 billion parameters. The 671B model is the original DeepSeek R1, while the smaller versions are distilled models based on Qwen and Llama architectures. If your hardware cannot support the full 671B model, you can run a smaller version by specifying the desired model size in the command. Replace <code>X</code> with the parameter size you want to use (e.g., 1.5b, 7b, 8b, 14b, 32b, 70b):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ollama run deepseek-r1:Xb
</span></span></code></pre></div><p>This flexibility allows you to utilize DeepSeek R1&rsquo;s capabilities even on hardware with limited resources.</p><h3 id=accessing-deepseek-r1-via-api>Accessing DeepSeek R1 via API<a hidden class=anchor aria-hidden=true href=#accessing-deepseek-r1-via-api>#</a></h3><p>Once the Ollama server is running, you can interact with DeepSeek R1 through an API. For example, using <code>curl</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>curl http://localhost:11434/api/chat -d <span class=s1>&#39;{
</span></span></span><span class=line><span class=cl><span class=s1>  &#34;model&#34;: &#34;deepseek-r1&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>  &#34;messages&#34;: [{ &#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Solve: 25 * 25&#34; }],
</span></span></span><span class=line><span class=cl><span class=s1>  &#34;stream&#34;: false
</span></span></span><span class=line><span class=cl><span class=s1>}&#39;</span>
</span></span></code></pre></div><p>This command sends a request to the model to solve the multiplication problem.</p><h3 id=using-deepseek-r1-in-python>Using DeepSeek R1 in Python<a hidden class=anchor aria-hidden=true href=#using-deepseek-r1-in-python>#</a></h3><p>To integrate DeepSeek R1 into Python applications, install the Ollama Python package:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>pip install ollama
</span></span></code></pre></div><p>Then, use the following script to interact with the model:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ollama</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>ollama</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;deepseek-r1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Explain Newton&#39;s second law of motion&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>][</span><span class=s2>&#34;content&#34;</span><span class=p>])</span>
</span></span></code></pre></div><p>This script sends a prompt to DeepSeek R1 and prints the model&rsquo;s response.</p><h2 id=considerations>Considerations<a hidden class=anchor aria-hidden=true href=#considerations>#</a></h2><p>While DeepSeek R1 offers advanced capabilities, it&rsquo;s important to be aware of certain considerations:</p><ul><li><strong>Content Moderation</strong>: Reports indicate that DeepSeek R1 may provide information that is potentially harmful or sensitive, such as details on modifying bird flu viruses or promoting self-harm. This raises concerns about the model&rsquo;s safety and the effectiveness of its content moderation mechanisms.</li><li><strong>Data Privacy</strong>: As with any AI model, it&rsquo;s crucial to handle data responsibly and be mindful of privacy implications, especially when deploying the model in applications that process sensitive information.</li></ul><h1 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h1><p>AI and LLMs are revolutionizing technology, and now you can run powerful AI models locally on your machine. Whether you prefer the command-line simplicity of Ollama or the user-friendly interface of LM Studio, local AI tools are becoming more accessible than ever. Experiment, explore, and harness the power of AI on your own terms!</p><p>Running AI models locally is an exciting opportunity for developers, researchers, and enthusiasts alike. It enables deeper control, improved privacy, and efficient experimentation without relying on cloud-based services. With advancements in hardware acceleration, running large-scale models on consumer machines is becoming more practical.</p><p>DeepSeek R1 is a powerful and cost-effective alternative to leading proprietary LLMs, making it an attractive choice for researchers, developers, and AI enthusiasts. By running it locally with Ollama, users can take advantage of its advanced reasoning capabilities while maintaining control over their AI infrastructure. Whether for coding, mathematics, or general problem-solving, DeepSeek R1 is a promising open-source solution for AI-driven applications.</p><hr><p>Article generated using artificial intelligence.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://blog.budzynskimaciej.pl/en/post/site-update-and-changes/><span class=title>Next »</span><br><span>Site Refresh and Update</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM? on x" href="https://x.com/intent/tweet/?text=AI%2c%20LocalLLM%20and%20DeepSeek.%20What%20is%20it%20all%20about%20and%20how%20to%20dive%20into%20the%20world%20of%20LLM%3f&amp;url=https%3a%2f%2fblog.budzynskimaciej.pl%2fen%2fpost%2fai-and-llms%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM? on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fblog.budzynskimaciej.pl%2fen%2fpost%2fai-and-llms%2f&amp;title=AI%2c%20LocalLLM%20and%20DeepSeek.%20What%20is%20it%20all%20about%20and%20how%20to%20dive%20into%20the%20world%20of%20LLM%3f&amp;summary=AI%2c%20LocalLLM%20and%20DeepSeek.%20What%20is%20it%20all%20about%20and%20how%20to%20dive%20into%20the%20world%20of%20LLM%3f&amp;source=https%3a%2f%2fblog.budzynskimaciej.pl%2fen%2fpost%2fai-and-llms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM? on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblog.budzynskimaciej.pl%2fen%2fpost%2fai-and-llms%2f&title=AI%2c%20LocalLLM%20and%20DeepSeek.%20What%20is%20it%20all%20about%20and%20how%20to%20dive%20into%20the%20world%20of%20LLM%3f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM? on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.budzynskimaciej.pl%2fen%2fpost%2fai-and-llms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM? on whatsapp" href="https://api.whatsapp.com/send?text=AI%2c%20LocalLLM%20and%20DeepSeek.%20What%20is%20it%20all%20about%20and%20how%20to%20dive%20into%20the%20world%20of%20LLM%3f%20-%20https%3a%2f%2fblog.budzynskimaciej.pl%2fen%2fpost%2fai-and-llms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM? on telegram" href="https://telegram.me/share/url?text=AI%2c%20LocalLLM%20and%20DeepSeek.%20What%20is%20it%20all%20about%20and%20how%20to%20dive%20into%20the%20world%20of%20LLM%3f&amp;url=https%3a%2f%2fblog.budzynskimaciej.pl%2fen%2fpost%2fai-and-llms%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM and DeepSeek. What is it all about and how to dive into the world of LLM? on ycombinator" href="https://news.ycombinator.com/submitlink?t=AI%2c%20LocalLLM%20and%20DeepSeek.%20What%20is%20it%20all%20about%20and%20how%20to%20dive%20into%20the%20world%20of%20LLM%3f&u=https%3a%2f%2fblog.budzynskimaciej.pl%2fen%2fpost%2fai-and-llms%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><div class="disqus markdown"><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://budzynskimaciej.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.budzynskimaciej.pl/en/>Budzyński Maciej - blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>