<!doctype html><html lang=pl dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM? | Budzyński Maciej - blog</title>
<meta name=keywords content><meta name=description content="Sztuczna inteligencja (AI) stała się jedną z najbardziej transformacyjnych technologii naszych czasów. Od chatbotów po autonomiczne pojazdy, AI zmienia branże i nasze codzienne życie. W tym artykule wyjaśnię, czym jest AI, jak działają duże modele językowe (LLM) i jak można uruchamiać modele AI lokalnie za pomocą narzędzi takich jak Ollama i LM Studio.
Czym jest sztuczna inteligencja?
Sztuczna inteligencja (AI) odnosi się do systemów komputerowych zdolnych do wykonywania zadań, które zazwyczaj wymagają ludzkiej inteligencji. Zadania te obejmują rozumienie języka naturalnego, rozpoznawanie obrazów, podejmowanie decyzji, a nawet generowanie kreatywnych treści. AI jest szeroko klasyfikowana na:"><meta name=author content="Maciej Budzyński"><link rel=canonical href=https://blog.budzynskimaciej.pl/post/ai-and-llms/><meta name=google-site-verification content="G-FTCMYPN4XN"><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=pl href=https://blog.budzynskimaciej.pl/post/ai-and-llms/><link rel=alternate hreflang=en href=https://blog.budzynskimaciej.pl/en/post/ai-and-llms/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://blog.budzynskimaciej.pl/post/ai-and-llms/"><meta property="og:site_name" content="Budzyński Maciej - blog"><meta property="og:title" content="AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM?"><meta property="og:description" content="Sztuczna inteligencja (AI) stała się jedną z najbardziej transformacyjnych technologii naszych czasów. Od chatbotów po autonomiczne pojazdy, AI zmienia branże i nasze codzienne życie. W tym artykule wyjaśnię, czym jest AI, jak działają duże modele językowe (LLM) i jak można uruchamiać modele AI lokalnie za pomocą narzędzi takich jak Ollama i LM Studio.
Czym jest sztuczna inteligencja? Sztuczna inteligencja (AI) odnosi się do systemów komputerowych zdolnych do wykonywania zadań, które zazwyczaj wymagają ludzkiej inteligencji. Zadania te obejmują rozumienie języka naturalnego, rozpoznawanie obrazów, podejmowanie decyzji, a nawet generowanie kreatywnych treści. AI jest szeroko klasyfikowana na:"><meta property="og:locale" content="pl-PL"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2025-02-10T18:00:00+02:00"><meta property="article:modified_time" content="2025-02-10T18:00:00+02:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM?"><meta name=twitter:description content="Sztuczna inteligencja (AI) stała się jedną z najbardziej transformacyjnych technologii naszych czasów. Od chatbotów po autonomiczne pojazdy, AI zmienia branże i nasze codzienne życie. W tym artykule wyjaśnię, czym jest AI, jak działają duże modele językowe (LLM) i jak można uruchamiać modele AI lokalnie za pomocą narzędzi takich jak Ollama i LM Studio.
Czym jest sztuczna inteligencja?
Sztuczna inteligencja (AI) odnosi się do systemów komputerowych zdolnych do wykonywania zadań, które zazwyczaj wymagają ludzkiej inteligencji. Zadania te obejmują rozumienie języka naturalnego, rozpoznawanie obrazów, podejmowanie decyzji, a nawet generowanie kreatywnych treści. AI jest szeroko klasyfikowana na:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.budzynskimaciej.pl/post/"},{"@type":"ListItem","position":2,"name":"AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM?","item":"https://blog.budzynskimaciej.pl/post/ai-and-llms/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM?","name":"AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM?","description":"Sztuczna inteligencja (AI) stała się jedną z najbardziej transformacyjnych technologii naszych czasów. Od chatbotów po autonomiczne pojazdy, AI zmienia branże i nasze codzienne życie. W tym artykule wyjaśnię, czym jest AI, jak działają duże modele językowe (LLM) i jak można uruchamiać modele AI lokalnie za pomocą narzędzi takich jak Ollama i LM Studio.\nCzym jest sztuczna inteligencja? Sztuczna inteligencja (AI) odnosi się do systemów komputerowych zdolnych do wykonywania zadań, które zazwyczaj wymagają ludzkiej inteligencji. Zadania te obejmują rozumienie języka naturalnego, rozpoznawanie obrazów, podejmowanie decyzji, a nawet generowanie kreatywnych treści. AI jest szeroko klasyfikowana na:\n","keywords":[],"articleBody":"Sztuczna inteligencja (AI) stała się jedną z najbardziej transformacyjnych technologii naszych czasów. Od chatbotów po autonomiczne pojazdy, AI zmienia branże i nasze codzienne życie. W tym artykule wyjaśnię, czym jest AI, jak działają duże modele językowe (LLM) i jak można uruchamiać modele AI lokalnie za pomocą narzędzi takich jak Ollama i LM Studio.\nCzym jest sztuczna inteligencja? Sztuczna inteligencja (AI) odnosi się do systemów komputerowych zdolnych do wykonywania zadań, które zazwyczaj wymagają ludzkiej inteligencji. Zadania te obejmują rozumienie języka naturalnego, rozpoznawanie obrazów, podejmowanie decyzji, a nawet generowanie kreatywnych treści. AI jest szeroko klasyfikowana na:\nWąska AI – Specjalistyczna AI zaprojektowana do określonych zadań, takich jak asystenci głosowi (Siri, Alexa) lub systemy rekomendacji. Ogólna AI – Hipotetyczna AI, która może wykonywać każde zadanie intelektualne, które może wykonać człowiek. Superinteligentna AI – Koncepcja, w której AI przewyższa inteligencję człowieka pod każdym względem. Czym są Duże Modele Językowe (LLM)? Duże modele językowe (LLM) to podzbiór AI zaprojektowany do rozumienia i generowania tekstu podobnego do ludzkiego. Modele te są trenowane na ogromnych ilościach danych tekstowych i wykorzystują techniki głębokiego uczenia się do przewidywania i generowania spójnych odpowiedzi. Popularne LLM obejmują:\nGPT (Generative Pre-trained Transformer) – Opracowany przez OpenAI. LLaMA (Large Language Model Meta AI) – Model typu open source autorstwa Meta. Mistral i Mixtral – Zaawansowane LLM skoncentrowane na wydajności i efektywności. Jak działają LLM LLM działają przy użyciu modeli głębokiego uczenia opartych na sieciach neuronowych, w szczególności architekturach transformatorowych. Kluczowe komponenty LLM obejmują:\nTokenizacja – dzielenie tekstu na mniejsze jednostki (tokeny) w celu przetworzenia. Szkolenie na dużych zestawach danych – uczenie się z miliardów słów. Dostrajanie – dostosowywanie modelu do określonych zadań, takich jak generowanie kodu lub tłumaczenie. Zastosowania LLM Duże modele językowe mają szeroki zakres zastosowań, w tym:\nSztuczna inteligencja konwersacyjna – używana w chatbotach, takich jak ChatGPT, agentach obsługi klienta i wirtualnych asystentach. Generowanie treści – pisanie artykułów na bloga, generowanie raportów, a nawet tworzenie poezji i fikcji. Pomoc w kodowaniu – asystenci kodowania wspomagani przez sztuczną inteligencję, tacy jak GitHub Copilot, pomagają programistom, generując fragmenty kodu i wykonując funkcje. Usługi tłumaczeniowe – automatyzacja tłumaczenia językowego za pomocą narzędzi, takich jak DeepL i Google Tłumacz. Badania medyczne – pomoc w diagnozowaniu schorzeń, podsumowywaniu prac medycznych i generowaniu notatek klinicznych. Wyszukiwanie i pobieranie informacji – ulepszanie wyszukiwarek dzięki podsumowywaniu wspomaganemu przez sztuczną inteligencję i kontekstowemu zrozumieniu. Wyzwania i ograniczenia Pomimo swoich możliwości, LLM-y mają również wyzwania i ograniczenia:\nTendencje w danych szkoleniowych – Ponieważ uczą się z ogromnych źródeł tekstowych, mogą dziedziczyć błędy występujące w tych zestawach danych. Wymagania obliczeniowe – Uruchamianie modeli na dużą skalę wymaga znacznej mocy obliczeniowej, szczególnie w przypadku aplikacji w czasie rzeczywistym. Brak prawdziwego zrozumienia – Podczas gdy LLM-y generują tekst na podstawie wzorców, nie posiadają prawdziwych zdolności rozumienia ani rozumowania. Obawy etyczne – Niewłaściwe wykorzystanie treści generowanych przez AI do dezinformacji, deepfake’ów lub plagiatu. W miarę kontynuowania badań, ulepszenia w zakresie bezpieczeństwa AI, wydajności i wytycznych etycznych będą kształtować przyszłość aplikacji LLM.\nLokalne uruchamianie modeli AI Podczas gdy większość aplikacji AI opiera się na modelach opartych na chmurze, lokalne uruchamianie modeli AI oferuje kilka korzyści:\nPrywatność – Twoje dane pozostają na Twoim komputerze. Prędkość – Brak zależności od połączenia internetowego. Dostosowanie – Możliwość dostrajania modeli do konkretnych przypadków użycia. Instalowanie i używanie lokalnych narzędzi AI 1. Ollama Ollama to narzędzie do uruchamiania LLM na komputerze lokalnym z minimalną konfiguracją.\nInstalacja Windows, Mac i Linux:\nPobierz plik wykonywalny z ollama.ai i zainstaluj go. Postępuj zgodnie z instrukcjami wyświetlanymi na ekranie, aby ukończyć instalację. Uruchamianie modelu ollama run mistral To polecenie pobiera i uruchamia lokalnie model Mistral. Ollama umożliwia wydajne ładowanie i uruchamianie różnych LLM przy jednoczesnym wykorzystaniu sprzętu.\nFunkcje Ollama Lekkie wykonywanie – Zoptymalizowane do wydajnego uruchamiania modeli. Obsługa wielu modeli – Ładowanie różnych LLM w razie potrzeby. Łatwość użytkowania – Prosty interfejs wiersza poleceń zapewniający szybki dostęp. 2. LM Studio LM Studio zapewnia interfejs graficzny do łatwego uruchamiania lokalnych modeli AI.\nInstalacja Pobierz LM Studio z lmstudio.ai i zainstaluj. Korzystanie z LM Studio Otwórz aplikację. Pobierz zgodny model (np. LLaMA 2, Mistral). Współdziałaj z modelem za pomocą wbudowanego interfejsu czatu. Funkcje LM Studio Przyjazny dla użytkownika interfejs – Brak konieczności interakcji z wierszem poleceń. Zarządzanie modelem – Łatwe pobieranie i przełączanie się między różnymi modelami AI. Optymalizacja wydajności – Zapewnia płynne działanie w różnych konfiguracjach sprzętowych. DeepSeek R1: Potężny LLM typu open source Czym jest DeepSeek R1? DeepSeek R1 to otwarty model dużego języka (LLM) opracowany przez chińską firmę AI DeepSeek. Zaprojektowany do doskonalenia złożonych zadań rozumowania, w tym matematyki, kodowania i logicznego rozwiązywania problemów, osiąga wydajność porównywalną z wiodącymi modelami, takimi jak GPT-4 firmy OpenAI. Co godne uwagi, DeepSeek R1 został opracowany przy znacznie mniejszej liczbie zasobów, wykorzystując tylko około 2000 procesorów graficznych i generując koszt około 5,6 miliona dolarów, co stanowi ułamek wydatków na podobne modele.\nWydajność W ocenach porównawczych DeepSeek R1 wykazał się wysoką wydajnością w różnych dziedzinach:\nMatematyka: Osiągnął wynik Pass@1 na poziomie 79,8% w teście porównawczym AIME 2024. Kodowanie: Wystąpił w zawodach w zadaniach związanych z kodowaniem, uzyskując wynik 49,2% w teście SWE-bench Verified, nieznacznie przewyższając GPT-4 OpenAI. Rozumowanie: Wykazał skuteczne zdolności logicznego rozumowania, co czyni go odpowiednim do złożonych aplikacji rozwiązywania problemów. Uruchamianie DeepSeek R1 lokalnie z Ollama Krok 1: Pobierz i uruchom DeepSeek R1 Otwórz terminal lub wiersz poleceń i wykonaj następujące polecenie, aby pobrać i uruchomić model DeepSeek R1:\nollama run deepseek-r1 To polecenie pobierze model DeepSeek R1 i uruchomi go lokalnie na Twoim komputerze.\nKrok 2: Uruchomienie DeepSeek R1 w tle Aby utrzymać DeepSeek R1 w ciągłym działaniu i dostępie przez API, uruchom serwer Ollama:\nollama serve Dzięki temu model będzie dostępny do integracji z innymi aplikacjami.\nRozważania dotyczące sprzętu DeepSeek R1 oferuje różne rozmiary modeli, od 1,5 miliarda do 671 miliardów parametrów. Model 671B to oryginalny DeepSeek R1, podczas gdy mniejsze wersje to modele destylowane oparte na architekturach Qwen i Llama. Jeśli Twój sprzęt nie obsługuje pełnego modelu 671B, możesz uruchomić mniejszą wersję, określając żądany rozmiar modelu w poleceniu. Zastąp X rozmiarem parametru, którego chcesz użyć (np. 1,5b, 7b, 8b, 14b, 32b, 70b):\nollama run deepseek-r1:Xb Ta elastyczność pozwala na wykorzystanie możliwości DeepSeek R1 nawet na sprzęcie o ograniczonych zasobach.\nDostęp do DeepSeek R1 za pośrednictwem API Po uruchomieniu serwera Ollama możesz wchodzić w interakcję z DeepSeek R1 za pośrednictwem API. Na przykład, używając curl:\ncurl http://localhost:11434/api/chat -d '{ \"model\": \"deepseek-r1\", \"messages\": [{ \"role\": \"user\", \"content\": \"Solve: 25 * 25\" }], \"stream\": false }' To polecenie wysyła żądanie do modelu w celu rozwiązania problemu mnożenia.\nUżywanie DeepSeek R1 w Pythonie Aby zintegrować DeepSeek R1 z aplikacjami Pythona, zainstaluj pakiet Ollama Python:\npip install ollama Następnie użyj następującego skryptu do interakcji z modelem:\nimport ollama response = ollama.chat( model=\"deepseek-r1\", messages=[ {\"role\": \"user\", \"content\": \"Explain Newton's second law of motion\"}, ], ) print(response[\"message\"][\"content\"]) Ten skrypt wysyła żądanie do DeepSeek R1 i zwraca odpowiedź modelu.\nRozważania Chociaż DeepSeek R1 oferuje zaawansowane możliwości, ważne jest, aby pamiętać o pewnych kwestiach:\nModerowanie treści: Raporty wskazują, że DeepSeek R1 może dostarczać informacje, które są potencjalnie szkodliwe lub wrażliwe, takie jak szczegóły dotyczące modyfikowania wirusów ptasiej grypy lub promowania samookaleczenia. Budzi to obawy o bezpieczeństwo modelu i skuteczność jego mechanizmów moderowania treści. Prywatność danych: Jak w przypadku każdego modelu AI, kluczowe jest odpowiedzialne obchodzenie się z danymi i pamiętanie o implikacjach prywatności, szczególnie podczas wdrażania modelu w aplikacjach przetwarzających poufne informacje. Wnioski AI i LLM rewolucjonizują technologię, a teraz możesz uruchamiać potężne modele AI lokalnie na swoim komputerze. Niezależnie od tego, czy wolisz prostotę wiersza poleceń Ollama, czy przyjazny dla użytkownika interfejs LM Studio, lokalne narzędzia AI stają się bardziej dostępne niż kiedykolwiek. Eksperymentuj, eksploruj i wykorzystuj moc AI na własnych warunkach!\nUruchamianie modeli AI lokalnie to ekscytująca okazja dla programistów, badaczy i entuzjastów. Umożliwia głębszą kontrolę, lepszą prywatność i wydajne eksperymentowanie bez polegania na usługach w chmurze. Dzięki postępom w akceleracji sprzętowej uruchamianie modeli na dużą skalę na komputerach konsumenckich staje się bardziej praktyczne.\nDeepSeek R1 to wydajna i niedroga alternatywa dla wiodących zastrzeżonych LLM, co czyni go atrakcyjnym wyborem dla badaczy, programistów i entuzjastów AI. Uruchamiając go lokalnie za pomocą Ollama, użytkownicy mogą skorzystać z jego zaawansowanych możliwości rozumowania, zachowując jednocześnie kontrolę nad swoją infrastrukturą AI. Niezależnie od tego, czy chodzi o kodowanie, matematykę czy ogólne rozwiązywanie problemów, DeepSeek R1 to obiecujące rozwiązanie typu open source dla aplikacji opartych na AI.\nArtykuł wygenerowany przy pomocy sztucznej inteligencji.\n","wordCount":"1376","inLanguage":"pl","datePublished":"2025-02-10T18:00:00+02:00","dateModified":"2025-02-10T18:00:00+02:00","author":{"@type":"Person","name":"Maciej Budzyński"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.budzynskimaciej.pl/post/ai-and-llms/"},"publisher":{"@type":"Organization","name":"Budzyński Maciej - blog","logo":{"@type":"ImageObject","url":"https://blog.budzynskimaciej.pl/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.budzynskimaciej.pl/ accesskey=h title="Home (Alt + H)"><img src=https://blog.budzynskimaciej.pl/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button><ul class=lang-switch><li>|</li><li><a href=https://blog.budzynskimaciej.pl/en/ title=English aria-label=English>English</a></li></ul></div></div><ul id=menu><li><a href=https://blog.budzynskimaciej.pl/about/ title="O mnie"><span>O mnie</span></a></li><li><a href=https://blog.budzynskimaciej.pl/projects/ title=Projekty><span>Projekty</span></a></li><li><a href=https://blog.budzynskimaciej.pl/archives/ title=Archiwa><span>Archiwa</span></a></li><li><a href=https://blog.budzynskimaciej.pl/search/ title=Szukaj><span>Szukaj</span></a></li><li><a href=https://blog.budzynskimaciej.pl/tags/ title=Tagi><span>Tagi</span></a></li><li><a href=https://budzynskimaciej.pl/ title=Portfolio><span>Portfolio</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.budzynskimaciej.pl/>Strona Główna</a>&nbsp;»&nbsp;<a href=https://blog.budzynskimaciej.pl/post/>Posts</a></div><h1 class="post-title entry-hint-parent">AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM?</h1><div class=post-meta><span title='2025-02-10 18:00:00 +0200 +0200'>10 lutego 2025</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;1376 słów&nbsp;·&nbsp;Maciej Budzyński&nbsp;|&nbsp;Tłumaczenia:<ul class=i18n_list><li><a href=https://blog.budzynskimaciej.pl/en/post/ai-and-llms/>English</a></li></ul>&nbsp;|&nbsp;<a href=https://github.com/BudzynskiMaciej/Personal-Blog-Source/blob/master/content/post/ai-and-llms.md rel="noopener noreferrer" target=_blank>Zaproponuj zmiany</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Spis treści</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#jak-działają-llm>Jak działają LLM</a><ul><li><a href=#zastosowania-llm>Zastosowania LLM</a></li><li><a href=#wyzwania-i-ograniczenia>Wyzwania i ograniczenia</a></li></ul></li></ul><ul><li><a href=#instalowanie-i-używanie-lokalnych-narzędzi-ai>Instalowanie i używanie lokalnych narzędzi AI</a><ul><li><a href=#1-ollama>1. Ollama</a></li><li><a href=#2-lm-studio>2. LM Studio</a></li></ul></li></ul><ul><li><a href=#czym-jest-deepseek-r1>Czym jest DeepSeek R1?</a><ul><li><a href=#wydajność>Wydajność</a></li></ul></li><li><a href=#uruchamianie-deepseek-r1-lokalnie-z-ollama>Uruchamianie DeepSeek R1 lokalnie z Ollama</a><ul><li><a href=#krok-1-pobierz-i-uruchom-deepseek-r1>Krok 1: Pobierz i uruchom DeepSeek R1</a></li><li><a href=#krok-2-uruchomienie-deepseek-r1-w-tle>Krok 2: Uruchomienie DeepSeek R1 w tle</a></li><li><a href=#rozważania-dotyczące-sprzętu>Rozważania dotyczące sprzętu</a></li><li><a href=#dostęp-do-deepseek-r1-za-pośrednictwem-api>Dostęp do DeepSeek R1 za pośrednictwem API</a></li><li><a href=#używanie-deepseek-r1-w-pythonie>Używanie DeepSeek R1 w Pythonie</a></li></ul></li><li><a href=#rozważania>Rozważania</a></li></ul></nav></div></details></div><div class=post-content><p>Sztuczna inteligencja (AI) stała się jedną z najbardziej transformacyjnych technologii naszych czasów. Od chatbotów po autonomiczne pojazdy, AI zmienia branże i nasze codzienne życie. W tym artykule wyjaśnię, czym jest AI, jak działają duże modele językowe (LLM) i jak można uruchamiać modele AI lokalnie za pomocą narzędzi takich jak Ollama i LM Studio.</p><h1 id=czym-jest-sztuczna-inteligencja>Czym jest sztuczna inteligencja?<a hidden class=anchor aria-hidden=true href=#czym-jest-sztuczna-inteligencja>#</a></h1><p>Sztuczna inteligencja (AI) odnosi się do systemów komputerowych zdolnych do wykonywania zadań, które zazwyczaj wymagają ludzkiej inteligencji. Zadania te obejmują rozumienie języka naturalnego, rozpoznawanie obrazów, podejmowanie decyzji, a nawet generowanie kreatywnych treści. AI jest szeroko klasyfikowana na:</p><ul><li><strong>Wąska AI</strong> – Specjalistyczna AI zaprojektowana do określonych zadań, takich jak asystenci głosowi (Siri, Alexa) lub systemy rekomendacji.</li><li><strong>Ogólna AI</strong> – Hipotetyczna AI, która może wykonywać każde zadanie intelektualne, które może wykonać człowiek.</li><li><strong>Superinteligentna AI</strong> – Koncepcja, w której AI przewyższa inteligencję człowieka pod każdym względem.</li></ul><h1 id=czym-są-duże-modele-językowe-llm>Czym są Duże Modele Językowe (LLM)?<a hidden class=anchor aria-hidden=true href=#czym-są-duże-modele-językowe-llm>#</a></h1><p>Duże modele językowe (LLM) to podzbiór AI zaprojektowany do rozumienia i generowania tekstu podobnego do ludzkiego. Modele te są trenowane na ogromnych ilościach danych tekstowych i wykorzystują techniki głębokiego uczenia się do przewidywania i generowania spójnych odpowiedzi. Popularne LLM obejmują:</p><ul><li><strong>GPT (Generative Pre-trained Transformer)</strong> – Opracowany przez OpenAI.</li><li><strong>LLaMA (Large Language Model Meta AI)</strong> – Model typu open source autorstwa Meta.</li><li><strong>Mistral i Mixtral</strong> – Zaawansowane LLM skoncentrowane na wydajności i efektywności.</li></ul><h2 id=jak-działają-llm>Jak działają LLM<a hidden class=anchor aria-hidden=true href=#jak-działają-llm>#</a></h2><p>LLM działają przy użyciu modeli głębokiego uczenia opartych na sieciach neuronowych, w szczególności architekturach transformatorowych. Kluczowe komponenty LLM obejmują:</p><ul><li><strong>Tokenizacja</strong> – dzielenie tekstu na mniejsze jednostki (tokeny) w celu przetworzenia.</li><li><strong>Szkolenie na dużych zestawach danych</strong> – uczenie się z miliardów słów.</li><li><strong>Dostrajanie</strong> – dostosowywanie modelu do określonych zadań, takich jak generowanie kodu lub tłumaczenie.</li></ul><h3 id=zastosowania-llm>Zastosowania LLM<a hidden class=anchor aria-hidden=true href=#zastosowania-llm>#</a></h3><p>Duże modele językowe mają szeroki zakres zastosowań, w tym:</p><ul><li><strong>Sztuczna inteligencja konwersacyjna</strong> – używana w chatbotach, takich jak ChatGPT, agentach obsługi klienta i wirtualnych asystentach.</li><li><strong>Generowanie treści</strong> – pisanie artykułów na bloga, generowanie raportów, a nawet tworzenie poezji i fikcji.</li><li><strong>Pomoc w kodowaniu</strong> – asystenci kodowania wspomagani przez sztuczną inteligencję, tacy jak GitHub Copilot, pomagają programistom, generując fragmenty kodu i wykonując funkcje.</li><li><strong>Usługi tłumaczeniowe</strong> – automatyzacja tłumaczenia językowego za pomocą narzędzi, takich jak DeepL i Google Tłumacz.</li><li><strong>Badania medyczne</strong> – pomoc w diagnozowaniu schorzeń, podsumowywaniu prac medycznych i generowaniu notatek klinicznych.</li><li><strong>Wyszukiwanie i pobieranie informacji</strong> – ulepszanie wyszukiwarek dzięki podsumowywaniu wspomaganemu przez sztuczną inteligencję i kontekstowemu zrozumieniu.</li></ul><h3 id=wyzwania-i-ograniczenia>Wyzwania i ograniczenia<a hidden class=anchor aria-hidden=true href=#wyzwania-i-ograniczenia>#</a></h3><p>Pomimo swoich możliwości, LLM-y mają również wyzwania i ograniczenia:</p><ul><li><strong>Tendencje w danych szkoleniowych</strong> – Ponieważ uczą się z ogromnych źródeł tekstowych, mogą dziedziczyć błędy występujące w tych zestawach danych.</li><li><strong>Wymagania obliczeniowe</strong> – Uruchamianie modeli na dużą skalę wymaga znacznej mocy obliczeniowej, szczególnie w przypadku aplikacji w czasie rzeczywistym.</li><li><strong>Brak prawdziwego zrozumienia</strong> – Podczas gdy LLM-y generują tekst na podstawie wzorców, nie posiadają prawdziwych zdolności rozumienia ani rozumowania.</li><li><strong>Obawy etyczne</strong> – Niewłaściwe wykorzystanie treści generowanych przez AI do dezinformacji, deepfake&rsquo;ów lub plagiatu.</li></ul><p>W miarę kontynuowania badań, ulepszenia w zakresie bezpieczeństwa AI, wydajności i wytycznych etycznych będą kształtować przyszłość aplikacji LLM.</p><h1 id=lokalne-uruchamianie-modeli-ai>Lokalne uruchamianie modeli AI<a hidden class=anchor aria-hidden=true href=#lokalne-uruchamianie-modeli-ai>#</a></h1><p>Podczas gdy większość aplikacji AI opiera się na modelach opartych na chmurze, lokalne uruchamianie modeli AI oferuje kilka korzyści:</p><ul><li><strong>Prywatność</strong> – Twoje dane pozostają na Twoim komputerze.</li><li><strong>Prędkość</strong> – Brak zależności od połączenia internetowego.</li><li><strong>Dostosowanie</strong> – Możliwość dostrajania modeli do konkretnych przypadków użycia.</li></ul><h2 id=instalowanie-i-używanie-lokalnych-narzędzi-ai>Instalowanie i używanie lokalnych narzędzi AI<a hidden class=anchor aria-hidden=true href=#instalowanie-i-używanie-lokalnych-narzędzi-ai>#</a></h2><h3 id=1-ollama>1. Ollama<a hidden class=anchor aria-hidden=true href=#1-ollama>#</a></h3><p>Ollama to narzędzie do uruchamiania LLM na komputerze lokalnym z minimalną konfiguracją.</p><h4 id=instalacja>Instalacja<a hidden class=anchor aria-hidden=true href=#instalacja>#</a></h4><p><strong>Windows, Mac i Linux:</strong></p><ul><li>Pobierz plik wykonywalny z <a href=https://ollama.ai/>ollama.ai</a> i zainstaluj go.</li><li>Postępuj zgodnie z instrukcjami wyświetlanymi na ekranie, aby ukończyć instalację.</li></ul><h4 id=uruchamianie-modelu>Uruchamianie modelu<a hidden class=anchor aria-hidden=true href=#uruchamianie-modelu>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ollama run mistral
</span></span></code></pre></div><p>To polecenie pobiera i uruchamia lokalnie model Mistral. Ollama umożliwia wydajne ładowanie i uruchamianie różnych LLM przy jednoczesnym wykorzystaniu sprzętu.</p><h4 id=funkcje-ollama>Funkcje Ollama<a hidden class=anchor aria-hidden=true href=#funkcje-ollama>#</a></h4><ul><li><strong>Lekkie wykonywanie</strong> – Zoptymalizowane do wydajnego uruchamiania modeli.</li><li><strong>Obsługa wielu modeli</strong> – Ładowanie różnych LLM w razie potrzeby.</li><li><strong>Łatwość użytkowania</strong> – Prosty interfejs wiersza poleceń zapewniający szybki dostęp.</li></ul><h3 id=2-lm-studio>2. LM Studio<a hidden class=anchor aria-hidden=true href=#2-lm-studio>#</a></h3><p>LM Studio zapewnia interfejs graficzny do łatwego uruchamiania lokalnych modeli AI.</p><h4 id=instalacja-1>Instalacja<a hidden class=anchor aria-hidden=true href=#instalacja-1>#</a></h4><ul><li>Pobierz LM Studio z <a href=https://lmstudio.ai/>lmstudio.ai</a> i zainstaluj.</li></ul><h4 id=korzystanie-z-lm-studio>Korzystanie z LM Studio<a hidden class=anchor aria-hidden=true href=#korzystanie-z-lm-studio>#</a></h4><ol><li>Otwórz aplikację.</li><li>Pobierz zgodny model (np. LLaMA 2, Mistral).</li><li>Współdziałaj z modelem za pomocą wbudowanego interfejsu czatu.</li></ol><h4 id=funkcje-lm-studio>Funkcje LM Studio<a hidden class=anchor aria-hidden=true href=#funkcje-lm-studio>#</a></h4><ul><li><strong>Przyjazny dla użytkownika interfejs</strong> – Brak konieczności interakcji z wierszem poleceń.</li><li><strong>Zarządzanie modelem</strong> – Łatwe pobieranie i przełączanie się między różnymi modelami AI.</li><li><strong>Optymalizacja wydajności</strong> – Zapewnia płynne działanie w różnych konfiguracjach sprzętowych.</li></ul><h1 id=deepseek-r1-potężny-llm-typu-open-source>DeepSeek R1: Potężny LLM typu open source<a hidden class=anchor aria-hidden=true href=#deepseek-r1-potężny-llm-typu-open-source>#</a></h1><h2 id=czym-jest-deepseek-r1>Czym jest DeepSeek R1?<a hidden class=anchor aria-hidden=true href=#czym-jest-deepseek-r1>#</a></h2><p>DeepSeek R1 to otwarty model dużego języka (LLM) opracowany przez chińską firmę AI DeepSeek. Zaprojektowany do doskonalenia złożonych zadań rozumowania, w tym matematyki, kodowania i logicznego rozwiązywania problemów, osiąga wydajność porównywalną z wiodącymi modelami, takimi jak GPT-4 firmy OpenAI. Co godne uwagi, DeepSeek R1 został opracowany przy znacznie mniejszej liczbie zasobów, wykorzystując tylko około 2000 procesorów graficznych i generując koszt około 5,6 miliona dolarów, co stanowi ułamek wydatków na podobne modele.</p><h3 id=wydajność>Wydajność<a hidden class=anchor aria-hidden=true href=#wydajność>#</a></h3><p>W ocenach porównawczych DeepSeek R1 wykazał się wysoką wydajnością w różnych dziedzinach:</p><ul><li><strong>Matematyka</strong>: Osiągnął wynik Pass@1 na poziomie 79,8% w teście porównawczym AIME 2024.</li><li><strong>Kodowanie</strong>: Wystąpił w zawodach w zadaniach związanych z kodowaniem, uzyskując wynik 49,2% w teście SWE-bench Verified, nieznacznie przewyższając GPT-4 OpenAI.</li><li><strong>Rozumowanie</strong>: Wykazał skuteczne zdolności logicznego rozumowania, co czyni go odpowiednim do złożonych aplikacji rozwiązywania problemów.</li></ul><h2 id=uruchamianie-deepseek-r1-lokalnie-z-ollama>Uruchamianie DeepSeek R1 lokalnie z Ollama<a hidden class=anchor aria-hidden=true href=#uruchamianie-deepseek-r1-lokalnie-z-ollama>#</a></h2><h3 id=krok-1-pobierz-i-uruchom-deepseek-r1>Krok 1: Pobierz i uruchom DeepSeek R1<a hidden class=anchor aria-hidden=true href=#krok-1-pobierz-i-uruchom-deepseek-r1>#</a></h3><p>Otwórz terminal lub wiersz poleceń i wykonaj następujące polecenie, aby pobrać i uruchomić model DeepSeek R1:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ollama run deepseek-r1
</span></span></code></pre></div><p>To polecenie pobierze model DeepSeek R1 i uruchomi go lokalnie na Twoim komputerze.</p><h3 id=krok-2-uruchomienie-deepseek-r1-w-tle>Krok 2: Uruchomienie DeepSeek R1 w tle<a hidden class=anchor aria-hidden=true href=#krok-2-uruchomienie-deepseek-r1-w-tle>#</a></h3><p>Aby utrzymać DeepSeek R1 w ciągłym działaniu i dostępie przez API, uruchom serwer Ollama:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ollama serve
</span></span></code></pre></div><p>Dzięki temu model będzie dostępny do integracji z innymi aplikacjami.</p><h3 id=rozważania-dotyczące-sprzętu>Rozważania dotyczące sprzętu<a hidden class=anchor aria-hidden=true href=#rozważania-dotyczące-sprzętu>#</a></h3><p>DeepSeek R1 oferuje różne rozmiary modeli, od 1,5 miliarda do 671 miliardów parametrów. Model 671B to oryginalny DeepSeek R1, podczas gdy mniejsze wersje to modele destylowane oparte na architekturach Qwen i Llama. Jeśli Twój sprzęt nie obsługuje pełnego modelu 671B, możesz uruchomić mniejszą wersję, określając żądany rozmiar modelu w poleceniu. Zastąp <code>X</code> rozmiarem parametru, którego chcesz użyć (np. 1,5b, 7b, 8b, 14b, 32b, 70b):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ollama run deepseek-r1:Xb
</span></span></code></pre></div><p>Ta elastyczność pozwala na wykorzystanie możliwości DeepSeek R1 nawet na sprzęcie o ograniczonych zasobach.</p><h3 id=dostęp-do-deepseek-r1-za-pośrednictwem-api>Dostęp do DeepSeek R1 za pośrednictwem API<a hidden class=anchor aria-hidden=true href=#dostęp-do-deepseek-r1-za-pośrednictwem-api>#</a></h3><p>Po uruchomieniu serwera Ollama możesz wchodzić w interakcję z DeepSeek R1 za pośrednictwem API. Na przykład, używając <code>curl</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>curl http://localhost:11434/api/chat -d <span class=s1>&#39;{
</span></span></span><span class=line><span class=cl><span class=s1>  &#34;model&#34;: &#34;deepseek-r1&#34;,
</span></span></span><span class=line><span class=cl><span class=s1>  &#34;messages&#34;: [{ &#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Solve: 25 * 25&#34; }],
</span></span></span><span class=line><span class=cl><span class=s1>  &#34;stream&#34;: false
</span></span></span><span class=line><span class=cl><span class=s1>}&#39;</span>
</span></span></code></pre></div><p>To polecenie wysyła żądanie do modelu w celu rozwiązania problemu mnożenia.</p><h3 id=używanie-deepseek-r1-w-pythonie>Używanie DeepSeek R1 w Pythonie<a hidden class=anchor aria-hidden=true href=#używanie-deepseek-r1-w-pythonie>#</a></h3><p>Aby zintegrować DeepSeek R1 z aplikacjami Pythona, zainstaluj pakiet Ollama Python:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>pip install ollama
</span></span></code></pre></div><p>Następnie użyj następującego skryptu do interakcji z modelem:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>ollama</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>ollama</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;deepseek-r1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Explain Newton&#39;s second law of motion&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>[</span><span class=s2>&#34;message&#34;</span><span class=p>][</span><span class=s2>&#34;content&#34;</span><span class=p>])</span>
</span></span></code></pre></div><p>Ten skrypt wysyła żądanie do DeepSeek R1 i zwraca odpowiedź modelu.</p><h2 id=rozważania>Rozważania<a hidden class=anchor aria-hidden=true href=#rozważania>#</a></h2><p>Chociaż DeepSeek R1 oferuje zaawansowane możliwości, ważne jest, aby pamiętać o pewnych kwestiach:</p><ul><li><strong>Moderowanie treści</strong>: Raporty wskazują, że DeepSeek R1 może dostarczać informacje, które są potencjalnie szkodliwe lub wrażliwe, takie jak szczegóły dotyczące modyfikowania wirusów ptasiej grypy lub promowania samookaleczenia. Budzi to obawy o bezpieczeństwo modelu i skuteczność jego mechanizmów moderowania treści.</li><li><strong>Prywatność danych</strong>: Jak w przypadku każdego modelu AI, kluczowe jest odpowiedzialne obchodzenie się z danymi i pamiętanie o implikacjach prywatności, szczególnie podczas wdrażania modelu w aplikacjach przetwarzających poufne informacje.</li></ul><h1 id=wnioski>Wnioski<a hidden class=anchor aria-hidden=true href=#wnioski>#</a></h1><p>AI i LLM rewolucjonizują technologię, a teraz możesz uruchamiać potężne modele AI lokalnie na swoim komputerze. Niezależnie od tego, czy wolisz prostotę wiersza poleceń Ollama, czy przyjazny dla użytkownika interfejs LM Studio, lokalne narzędzia AI stają się bardziej dostępne niż kiedykolwiek. Eksperymentuj, eksploruj i wykorzystuj moc AI na własnych warunkach!</p><p>Uruchamianie modeli AI lokalnie to ekscytująca okazja dla programistów, badaczy i entuzjastów. Umożliwia głębszą kontrolę, lepszą prywatność i wydajne eksperymentowanie bez polegania na usługach w chmurze. Dzięki postępom w akceleracji sprzętowej uruchamianie modeli na dużą skalę na komputerach konsumenckich staje się bardziej praktyczne.</p><p>DeepSeek R1 to wydajna i niedroga alternatywa dla wiodących zastrzeżonych LLM, co czyni go atrakcyjnym wyborem dla badaczy, programistów i entuzjastów AI. Uruchamiając go lokalnie za pomocą Ollama, użytkownicy mogą skorzystać z jego zaawansowanych możliwości rozumowania, zachowując jednocześnie kontrolę nad swoją infrastrukturą AI. Niezależnie od tego, czy chodzi o kodowanie, matematykę czy ogólne rozwiązywanie problemów, DeepSeek R1 to obiecujące rozwiązanie typu open source dla aplikacji opartych na AI.</p><hr><p>Artykuł wygenerowany przy pomocy sztucznej inteligencji.</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://blog.budzynskimaciej.pl/post/site-update-and-changes/><span class=title>Następna »</span><br><span>Odświeżenie i aktualizacja strony</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM? on x" href="https://x.com/intent/tweet/?text=AI%2c%20LocalLLM%20i%20DeepSeek.%20O%20co%20chodzi%20i%20jak%20zanurzy%c4%87%20si%c4%99%20w%20%c5%9bwiecie%20LLM%3f&amp;url=https%3a%2f%2fblog.budzynskimaciej.pl%2fpost%2fai-and-llms%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM? on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fblog.budzynskimaciej.pl%2fpost%2fai-and-llms%2f&amp;title=AI%2c%20LocalLLM%20i%20DeepSeek.%20O%20co%20chodzi%20i%20jak%20zanurzy%c4%87%20si%c4%99%20w%20%c5%9bwiecie%20LLM%3f&amp;summary=AI%2c%20LocalLLM%20i%20DeepSeek.%20O%20co%20chodzi%20i%20jak%20zanurzy%c4%87%20si%c4%99%20w%20%c5%9bwiecie%20LLM%3f&amp;source=https%3a%2f%2fblog.budzynskimaciej.pl%2fpost%2fai-and-llms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM? on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fblog.budzynskimaciej.pl%2fpost%2fai-and-llms%2f&title=AI%2c%20LocalLLM%20i%20DeepSeek.%20O%20co%20chodzi%20i%20jak%20zanurzy%c4%87%20si%c4%99%20w%20%c5%9bwiecie%20LLM%3f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM? on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fblog.budzynskimaciej.pl%2fpost%2fai-and-llms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM? on whatsapp" href="https://api.whatsapp.com/send?text=AI%2c%20LocalLLM%20i%20DeepSeek.%20O%20co%20chodzi%20i%20jak%20zanurzy%c4%87%20si%c4%99%20w%20%c5%9bwiecie%20LLM%3f%20-%20https%3a%2f%2fblog.budzynskimaciej.pl%2fpost%2fai-and-llms%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM? on telegram" href="https://telegram.me/share/url?text=AI%2c%20LocalLLM%20i%20DeepSeek.%20O%20co%20chodzi%20i%20jak%20zanurzy%c4%87%20si%c4%99%20w%20%c5%9bwiecie%20LLM%3f&amp;url=https%3a%2f%2fblog.budzynskimaciej.pl%2fpost%2fai-and-llms%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share AI, LocalLLM i DeepSeek. O co chodzi i jak zanurzyć się w świecie LLM? on ycombinator" href="https://news.ycombinator.com/submitlink?t=AI%2c%20LocalLLM%20i%20DeepSeek.%20O%20co%20chodzi%20i%20jak%20zanurzy%c4%87%20si%c4%99%20w%20%c5%9bwiecie%20LLM%3f&u=https%3a%2f%2fblog.budzynskimaciej.pl%2fpost%2fai-and-llms%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><div class="disqus markdown"><div id=disqus_thread></div><script>(function(){var e=document,t=e.createElement("script");t.src="https://budzynskimaciej.disqus.com/embed.js",t.setAttribute("data-timestamp",+new Date),(e.head||e.body).appendChild(t)})()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by
Disqus.</a></noscript></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://blog.budzynskimaciej.pl/>Budzyński Maciej - blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="Kopiuj";function s(){t.innerHTML="Skopiowano!",setTimeout(()=>{t.innerHTML="Kopiuj"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>